{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quora-Question-Pair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('qq-train.csv').fillna(\"\")\n",
    "np_data = data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Questions with qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1, q2 = data[['qid1', 'question1']], data[['qid2', 'question2']]\n",
    "q1.columns = ['qid', 'question']\n",
    "q2.columns = ['qid', 'question']\n",
    "question_data = pd.concat((q1, q2), axis=0).fillna(\"\").sort_values(by='qid').drop_duplicates('qid').values\n",
    "for i in range(10):\n",
    "    print('{}: {}'.format(question_data[i, 0], question_data[i, 1]))\n",
    "print('...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = TfidfVectorizer(max_features = 4096).fit_transform(question_data[:,1]).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_data = np.zeros((data.shape[0], vectors.shape[1]))\n",
    "for i in range(data.shape[0]):\n",
    "    vector_data[i] = vectors[np_data[i,1]-1] - vectors[np_data[i,2]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified Sampling 25% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vector_data, np_data[:,-1].astype('int'),\n",
    "                                                    test_size=0.75, random_state=10,\n",
    "                                                    stratify=np_data[:,-1].astype('int'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = set(np.nonzero(X_train[0])[0].tolist())\n",
    "# for i in range(1, X_train.shape[0]):\n",
    "#     s = s.union(set(np.nonzero(X_train[i])[0].tolist()))\n",
    "# np.median(np.count_nonzero(X_train, axis=1))\n",
    "# print(len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=12, random_state=10)\n",
    "pca = pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "fig.set_figheight(6)\n",
    "fig.set_figwidth(8)\n",
    "axes.set_title('Variance Explanation vs Eigen Vectors')\n",
    "axes.set_xlabel('Eigen Vectors')\n",
    "axes.set_ylabel('Explained Variance')\n",
    "axes.plot(np.cumsum(pca.explained_variance_))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "g_X = pca.transform(X_train)\n",
    "for train_index, _ in skf.split(X_train, y_train):\n",
    "    clf.partial_fit(g_X[train_index], y_train[train_index], [0,1])\n",
    "    print('.', end='')\n",
    "y_pred = clf.predict(pca.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C':[0.001, 0.01, 0.1, 1, 10, 100]\n",
    "}\n",
    "logistic = LogisticRegression(penalty='l1', solver='saga')\n",
    "clf = GridSearchCV(logistic, param_grid,\n",
    "                   ['accuracy'],\n",
    "                   cv=5, refit='accuracy', verbose=1, n_jobs=4)\n",
    "\n",
    "g_X = pca.transform(X_train)\n",
    "print(g_X.shape)\n",
    "clf.fit(g_X, y_train)\n",
    "y_pred = clf.predict(pca.transform(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C':[0.001, 0.01, 0.1, 1, 10, 100],\n",
    "     'kernel':['linear', 'sigmoid', 'rbf', 'poly'],\n",
    "     'degree':[2,3],\n",
    "     'gamma': [0.1,0.3,0.5,0.7,0.9],\n",
    "     'coef0': [0.1,0.5,1.0,1.5,5.0,10.0]}\n",
    "]\n",
    "\n",
    "svc = SVC(random_state=10)\n",
    "clf = GridSearchCV(svc, param_grid,\n",
    "                   ['f1', 'accuracy', 'recall', 'precision'],\n",
    "                   cv=5, refit='accuracy', verbose=1, n_jobs=4)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(pca.transform(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(f1_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
